{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0,3495  0,6793  0,5830\n",
       " 0,0566  0,1540  0,8538\n",
       " 0,5578  0,3272  0,7556\n",
       " 0,8243  0,1743  0,7137\n",
       " 0,2077  0,0563  0,4037\n",
       "[torch.DoubleTensor of size 5x3]\n",
       "\n",
       " 0,1507  0,6136  0,9058  0,4814\n",
       " 0,8861  0,4037  0,7192  0,0512\n",
       " 0,7810  0,6285  0,8220  0,3151\n",
       "[torch.DoubleTensor of size 3x4]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 1,1100  0,8551  1,2844  0,3867\n",
       " 0,8119  0,6335  0,8639  0,3042\n",
       " 0,9642  0,9492  1,3618  0,5234\n",
       " 0,8361  1,0246  1,4587  0,6306\n",
       " 0,3965  0,4039  0,5605  0,2301\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(5,3)\n",
    "a = torch.rand(5,3)\n",
    "print(a)\n",
    "b = torch.rand(3,4)\n",
    "print(b)\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAAAiCAAAAAChVs4GAAAApklEQVRYhe2XwQ2EMAwE14hS6A6aSE3QBkXwoQS+3IfDwopJEDrdPjyPrFACGtkIYdnBQXukALh3Kp94RfO7Rz+DRkRY3hGaioSI5RRZ13wq05hPJaV81vD9jmBzUlmcVGYna+Brzb8JEUuIWELEEiKWELGEiCVELDQirbfRle4UYCjOhvXTCk1FaETO1hRbgQG9XsixXkp/+a3PnvChqQiNCM0Q/gEqHiATpbi9aAAAAABJRU5ErkJggg==",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 34,
       "width": 136
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "require 'nn'\n",
    "require 'torch'\n",
    "img = image.load('52.png'):float()\n",
    "print(img)\n",
    "itorch.image(img)\n",
    "--[[\n",
    "\n",
    "input = torch.rand(1,32,32) \n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "net:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.Linear(120, 84))\n",
    "net:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "net:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "\n",
    "print('Lenet5\\n' .. net:__tostring());\n",
    "output = net:forward(input)\n",
    "print(\"-------------\")\n",
    "print(output)\n",
    "net:zeroGradParameters()\n",
    "gradInput = net:backward(input, torch.rand(10))\n",
    "print(#gradInput)\n",
    "]]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
