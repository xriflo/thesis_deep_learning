
 160
   3
  32
  32
[torch.LongStorage of size 4]

[0m==> preprocessing data: colorspace RGB -> YUV[0m	
[0maici[0m	
[0maici[0m	
[0maici[0m	
[0maici[0m	
[0m------original labels-----[0m	
[0m------log labels----------[0m	
-4.7086 -4.4887 -4.6118 -4.6027
-7.4700 -7.3218 -7.3730 -7.4344
 3.5639  3.9810  3.5096  3.3869
-2.3522 -2.3087 -2.1959 -2.1339
 3.3183  3.3212  3.3014  3.4254
-4.8460 -4.8000 -4.7962 -4.8024
 2.5184  2.3632  2.4045  2.0001
 4.1979  4.1678  4.1616  4.2461
 3.8871  3.8126  3.8075  3.7732
-4.1007 -4.1316 -3.4831 -4.7517
-4.5222 -6.6252 -5.9701 -5.4704
-5.6020 -5.7010 -5.5712 -5.7688
 1.1242  0.7464  0.5465  0.9179
 3.2127  3.2381  3.3228  3.2230
 3.1838  3.2463  3.3618  3.4713
 3.7507  3.7538  3.8358  3.7344
 3.0592  2.2777  2.0302  2.1734
-9.0420 -8.7412 -8.9523 -8.7720
 3.3288  3.5703  3.2854  3.8165
 1.7911  2.1374  2.3289  1.8727
-2.9568 -2.6465 -2.8221 -2.8560
 3.4767  3.3695  3.3322  3.3785
 3.0586  3.2427  3.3065  2.9318
 0.6757  0.8978  1.1335  0.8041
 3.8139  4.1327  3.8564  3.7527
-6.3235 -6.3581 -6.2374 -6.7157
 3.1103  3.0156  2.9768  3.2731
 3.8620  3.8732  3.9384  3.8428
 3.5122  3.4368  3.6496  3.5886
-5.4031 -5.5366 -5.5673 -5.6602
 3.4591  3.0365  2.8054  2.8349
-5.2309 -5.0427 -5.0502 -5.2433
 3.6819  3.5906  3.5843  3.5351
-1.8824 -2.1923 -1.9019 -1.7234
-2.4574 -2.5382 -1.6686 -2.6710
 3.6384  3.6523  3.7332  3.5760
-5.2164 -5.3878 -5.5772 -5.4489
 0.5945  0.6369  0.2836  0.4973
-7.5967 -7.6383 -7.6127 -7.6055
 4.5085  4.4959  4.5539  4.4872
 3.7376  3.6838  3.6942  3.8073
-3.2277 -3.2243 -3.3653 -3.5325
-1.3970 -1.5008 -1.2199 -1.1958
-3.4007 -3.0806 -3.2788 -3.2523
 0.8628  0.8788  0.9198  0.9328
 4.4177  4.3770  4.4449  4.3692
-5.9587 -5.9652 -5.6798 -5.9697
 2.3082  2.1766  2.1255  2.8922
-4.5690 -4.3423 -4.7126 -4.6603
 3.2935  3.2154  3.3803  3.2499
-6.4478 -6.2633 -6.3329 -6.6412
 4.5026  4.4348  4.4465  4.4100
 0.1794  0.1325  0.1699 -0.0388
-3.4703 -2.9235 -2.5072 -1.3027
-6.9784 -7.0701 -6.5832 -7.0669
-0.4355 -0.4993  0.4232 -0.7508
-6.9881 -7.0221 -6.8692 -6.9532
-4.8589 -4.7898 -4.8228 -4.7941
-7.2438 -7.4367 -7.0858 -7.3323
-7.0418 -6.8877 -7.1630 -6.9310
-0.8319  0.6311 -0.9451 -0.8020
-6.8727 -6.8510 -6.5283 -6.8939
 4.0748  4.0590  4.1435  4.0703
 3.8161  3.8427  3.8056  3.9139
-2.2635 -1.8562 -1.9956 -2.3936
-6.6741 -7.1338 -7.0485 -6.9383
 0.8511  1.0366  0.8917  1.0170
 2.2971  1.9399  2.8390  2.1078
-7.4924 -7.4607 -7.5820 -7.7526
-7.8364 -7.9251 -7.9313 -7.9819
 2.8570  2.9700  2.9195  3.1579
-4.8237 -4.8375 -4.6935 -4.8574
-3.2866 -2.4881 -3.1832 -3.6333
-0.6945 -0.5139 -0.4763 -0.6563
 1.4286  1.1180  2.1760  1.1478
-5.1374 -4.9091 -5.1227 -4.7947
 3.6991  3.7845  3.6551  3.6634
-8.7139 -8.5276 -8.6009 -8.6368
 4.2974  4.2297  4.1984  4.2181
 3.9906  3.9642  4.0409  3.9543
 4.5070  4.4645  4.4907  4.5463
-4.0583 -4.1056 -4.7688 -3.4926
-8.3824 -8.2705 -8.3956 -8.5073
-0.9613 -0.8425 -1.0121 -1.0694
-0.5381 -2.2016 -1.1744 -1.8546
-4.9582 -4.4608 -4.8215 -4.6878
 1.4992  1.6448  1.2655  1.8533
-7.3896 -7.5562 -7.2581 -7.7519
-5.1027 -5.5153 -4.8827 -5.2389
 1.6125  1.9934  1.5639  1.2297
 3.2715  3.1716  3.1734  3.1304
-3.6300 -3.8002 -3.9056 -3.9577
-1.2413 -1.2268 -1.1135 -1.2344
-4.0939 -4.1141 -4.2230 -4.1638
-4.5113 -4.2587 -4.2654 -4.1646
-4.1612 -4.1924 -4.3418 -4.2791
 4.0922  4.0142  4.0069  3.9923
-8.5002 -8.2958 -8.3622 -8.4757
-4.9753 -4.9009 -4.9834 -4.9460
-8.0711 -7.9672 -8.0936 -8.0961
 4.3324  4.4000  4.3059  4.3200
 4.3874  4.3903  4.4029  4.4513
-7.7442 -7.6395 -7.5957 -7.7459
 3.0300  3.4224  2.8251  2.5245
 3.9438  3.9152  3.9344  4.0169
 4.4838  4.3259  4.3162  4.3753
 4.1709  4.1013  4.0929  4.2961
 4.1343  3.9949  4.3321  4.1242
-0.4930 -0.4566 -0.2750  0.4396
 3.0655  3.2009  3.1114  3.4584
 1.1771  1.4610  1.3554  1.2720
 4.2669  4.2826  4.2723  4.3487
-7.9643 -8.1838 -8.0038 -7.8942
 4.0408  4.0243  4.0020  4.1257
 4.2586  4.3034  4.3371  4.2719
-6.3264 -6.1045 -6.6288 -6.4668
-0.4368 -0.3534 -0.2383 -0.5006
 3.3857  3.4375  3.5927  3.4505
-8.6336 -8.4521 -8.6959 -8.6318
-7.5930 -7.5651 -7.5342 -7.6161
-7.8385 -7.7368 -7.7447 -7.7850
 3.2203  3.5354  3.8507  3.4447
 3.2256  3.4156  3.1507  3.6377
-2.1400 -2.2484 -2.1605 -2.1204
 0.5702  1.8995  0.7376  0.2738
-7.5213 -7.0299 -7.5200 -7.1919
 2.5688  3.1907  2.2098  2.6000
 0.7528  1.3361  0.9316  2.2076
-4.3594 -5.2037 -4.7968 -5.2622
-6.0084 -6.0213 -5.8289 -6.0701
 3.4331  3.4186  3.4087  3.5280
-3.8503 -3.8837 -3.7858 -3.9694
-7.9752 -8.1426 -7.9201 -8.0437
 4.1324  4.1948  4.0882  4.1218
 3.4868  3.5793  3.4630  3.5000
 1.6092  1.9659  1.4352  2.4091
 3.3403  3.3286  3.4852  3.2982
 4.1418  4.1485  4.2284  4.1532
 4.0114  3.7056  3.6503  3.7279
 2.9629  2.9625  3.1547  2.9036
 3.5530  3.5380  3.5340  3.6306
-8.0855 -7.9121 -7.7828 -8.1254
-4.3792 -3.6085 -4.3128 -3.6012
 2.0048  2.2618  1.6727  2.7288
 1.0801  1.3107  1.5822  0.8855
 3.2661  3.3741  3.2254  3.2956
 3.9211  3.9897  3.9099  3.8828
 0.3200  0.2639  0.5604  0.2244
-9.0210 -8.8577 -8.9159 -8.8020
-6.9078 -6.9078 -6.9078 -6.9078
 1.7712  1.7312  2.4682  2.0350
-4.5474 -4.1833 -4.1081 -4.3302
-7.9721 -7.9695 -8.2058 -8.0609
-7.5376 -7.7138 -7.6451 -7.7644
 1.9005  1.9248  2.1057  1.9869
-5.9751 -6.0048 -5.8843 -5.9192
 4.5814  4.6052  4.5417  4.5275
-6.9056 -7.1389 -6.1942 -7.0388
-2.4392 -2.6105 -2.0180 -2.2314
-7.9651 -7.5065 -7.2431 -7.6250
[torch.DoubleTensor of size 160x4]

[0m==> preprocessing data: normalize each feature (channel) globally[0m	
[0m------norm to 0, 1--------[0m	
 0.3175  0.3336  0.3246  0.3253
 0.1152  0.1261  0.1223  0.1178
 0.9237  0.9543  0.9197  0.9107
 0.4902  0.4934  0.5017  0.5062
 0.9057  0.9059  0.9045  0.9136
 0.3075  0.3108  0.3111  0.3107
 0.8471  0.8357  0.8387  0.8091
 0.9702  0.9680  0.9675  0.9737
 0.9474  0.9419  0.9416  0.9390
 0.3621  0.3598  0.4073  0.3144
 0.3312  0.1771  0.2251  0.2617
 0.2521  0.2448  0.2543  0.2398
 0.7449  0.7172  0.7026  0.7298
 0.8980  0.8998  0.9060  0.8987
 0.8959  0.9004  0.9089  0.9169
 0.9374  0.9376  0.9436  0.9362
 0.8867  0.8295  0.8113  0.8218
 0.0000  0.0220  0.0066  0.0198
 0.9065  0.9242  0.9033  0.9422
 0.7938  0.8192  0.8332  0.7998
 0.4459  0.4686  0.4558  0.4533
 0.9173  0.9095  0.9067  0.9101
 0.8867  0.9002  0.9048  0.8774
 0.7121  0.7283  0.7456  0.7215
 0.9420  0.9654  0.9451  0.9375
 0.1992  0.1967  0.2055  0.1705
 0.8905  0.8835  0.8807  0.9024
 0.9455  0.9464  0.9511  0.9441
 0.9199  0.9144  0.9300  0.9255
 0.2666  0.2569  0.2546  0.2478
 0.9160  0.8851  0.8681  0.8703
 0.2793  0.2931  0.2925  0.2784
 0.9323  0.9257  0.9252  0.9216
 0.5246  0.5019  0.5232  0.5363
 0.4825  0.4766  0.5403  0.4668
 0.9292  0.9302  0.9361  0.9246
 0.2803  0.2678  0.2539  0.2633
 0.7061  0.7092  0.6833  0.6990
 0.1059  0.1029  0.1047  0.1053
 0.9929  0.9920  0.9962  0.9914
 0.9364  0.9325  0.9332  0.9415
 0.4260  0.4263  0.4160  0.4037
 0.5602  0.5526  0.5732  0.5749
 0.4134  0.4368  0.4223  0.4242
 0.7258  0.7269  0.7300  0.7309
 0.9863  0.9833  0.9883  0.9827
 0.2259  0.2255  0.2464  0.2251
 0.8317  0.8220  0.8183  0.8745
 0.3278  0.3444  0.3172  0.3211
 0.9039  0.8982  0.9102  0.9007
 0.1901  0.2036  0.1985  0.1759
 0.9925  0.9875  0.9884  0.9857
 0.6757  0.6723  0.6750  0.6597
 0.4083  0.4483  0.4788  0.5671
 0.1512  0.1445  0.1802  0.1447
 0.6306  0.6260  0.6936  0.6075
 0.1505  0.1480  0.1592  0.1531
 0.3065  0.3116  0.3092  0.3113
 0.1318  0.1176  0.1433  0.1253
 0.1466  0.1579  0.1377  0.1547
 0.6016  0.7088  0.5933  0.6038
 0.1590  0.1606  0.1842  0.1574
 0.9611  0.9600  0.9662  0.9608
 0.9422  0.9441  0.9414  0.9494
 0.4967  0.5265  0.5163  0.4872
 0.1735  0.1398  0.1461  0.1542
 0.7249  0.7385  0.7279  0.7371
 0.8309  0.8047  0.8706  0.8170
 0.1136  0.1159  0.1070  0.0945
 0.0883  0.0818  0.0814  0.0777
 0.8719  0.8802  0.8765  0.8940
 0.3091  0.3081  0.3186  0.3066
 0.4217  0.4802  0.4293  0.3963
 0.6117  0.6249  0.6277  0.6145
 0.7672  0.7445  0.8220  0.7467
 0.2861  0.3028  0.2872  0.3112
 0.9336  0.9399  0.9304  0.9310
 0.0240  0.0377  0.0323  0.0297
 0.9774  0.9725  0.9702  0.9716
 0.9550  0.9530  0.9587  0.9523
 0.9928  0.9897  0.9916  0.9957
 0.3652  0.3617  0.3131  0.4066
 0.0483  0.0565  0.0474  0.0392
 0.5921  0.6008  0.5884  0.5842
 0.6231  0.5012  0.5765  0.5267
 0.2992  0.3357  0.3093  0.3191
 0.7724  0.7831  0.7553  0.7984
 0.1211  0.1089  0.1307  0.0945
 0.2887  0.2584  0.3048  0.2787
 0.7807  0.8086  0.7772  0.7527
 0.9023  0.8950  0.8951  0.8919
 0.3966  0.3841  0.3764  0.3726
 0.5716  0.5727  0.5810  0.5721
 0.3626  0.3611  0.3531  0.3575
 0.3320  0.3505  0.3500  0.3574
 0.3576  0.3554  0.3444  0.3490
 0.9624  0.9567  0.9562  0.9551
 0.0397  0.0547  0.0498  0.0415
 0.2980  0.3034  0.2974  0.3001
 0.0711  0.0788  0.0695  0.0693
 0.9800  0.9850  0.9781  0.9791
 0.9840  0.9843  0.9852  0.9887
 0.0951  0.1028  0.1060  0.0950
 0.8846  0.9133  0.8696  0.8475
 0.9515  0.9494  0.9508  0.9569
 0.9911  0.9795  0.9788  0.9832
 0.9682  0.9631  0.9625  0.9774
 0.9655  0.9553  0.9800  0.9648
 0.6264  0.6291  0.6424  0.6948
 0.8872  0.8971  0.8905  0.9160
 0.7488  0.7696  0.7619  0.7558
 0.9752  0.9764  0.9756  0.9812
 0.0790  0.0629  0.0761  0.0841
 0.9586  0.9574  0.9558  0.9649
 0.9746  0.9779  0.9804  0.9756
 0.1990  0.2152  0.1768  0.1887
 0.6305  0.6367  0.6451  0.6259
 0.9106  0.9144  0.9258  0.9154
 0.0299  0.0432  0.0254  0.0301
 0.1062  0.1082  0.1105  0.1045
 0.0882  0.0956  0.0951  0.0921
 0.8985  0.9216  0.9447  0.9150
 0.8989  0.9128  0.8934  0.9291
 0.5057  0.4978  0.5042  0.5072
 0.7043  0.8017  0.7166  0.6826
 0.1114  0.1474  0.1115  0.1356
 0.8508  0.8964  0.8245  0.8531
 0.7177  0.7605  0.7308  0.8243
 0.3431  0.2813  0.3111  0.2770
 0.2223  0.2213  0.2354  0.2178
 0.9141  0.9131  0.9123  0.9211
 0.3804  0.3780  0.3851  0.3717
 0.0782  0.0659  0.0822  0.0732
 0.9654  0.9699  0.9621  0.9646
 0.9180  0.9248  0.9163  0.9190
 0.7805  0.8066  0.7677  0.8391
 0.9073  0.9065  0.9179  0.9042
 0.9660  0.9665  0.9724  0.9669
 0.9565  0.9341  0.9300  0.9357
 0.8797  0.8796  0.8937  0.8753
 0.9229  0.9218  0.9215  0.9286
 0.0701  0.0828  0.0923  0.0672
 0.3417  0.3981  0.3465  0.3987
 0.8095  0.8283  0.7851  0.8625
 0.7417  0.7586  0.7785  0.7274
 0.9019  0.9098  0.8989  0.9040
 0.9499  0.9549  0.9491  0.9471
 0.6860  0.6819  0.7036  0.6790
 0.0015  0.0135  0.0092  0.0176
 0.1564  0.1564  0.1564  0.1564
 0.7923  0.7894  0.8434  0.8117
 0.3293  0.3560  0.3615  0.3453
 0.0784  0.0786  0.0613  0.0719
 0.1102  0.0973  0.1024  0.0936
 0.8018  0.8036  0.8168  0.8081
 0.2247  0.2226  0.2314  0.2288
 0.9983  1.0000  0.9954  0.9943
 0.1565  0.1395  0.2087  0.1468
 0.4838  0.4713  0.5147  0.4991
 0.0789  0.1125  0.1318  0.1038
[torch.DoubleTensor of size 160x4]

[0m==> preprocessing data: normalize all three channels locally[0m	
[0m==> verify statistics[0m	
[0mtraining data, y-channel, mean: 0.019399766744573[0m	
[0mtraining data, y-channel, standard deviation: 0.67018418535844[0m	
[0mtraining data, u-channel, mean: -0.0021570480859497[0m	
[0mtraining data, u-channel, standard deviation: 0.70548865434893[0m	
[0mtraining data, v-channel, mean: -0.01915354823883[0m	
[0mtraining data, v-channel, standard deviation: 0.56490965717759[0m	
[0m==> visualizing data[0m	
