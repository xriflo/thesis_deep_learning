\chapter{Introduction}
\label{chapter:intro}

\section{Motivation}
\label{sec:motivation}
Humans have always felt the need to explore and find a way to a better life. Starting with stone tools (2.6 million years ago) and continuing with personal computers are only some proof in human evolution. Lately, we have discovered Machine Learning which have the purpose to allow machines for learning to do different tasks.

Deep learning is a subfield of machine learning area and it is inspired by how the human brain works. Through deep learning, we are trying to solve some of the most pressuring human problems as cancer classification (benign or malignant tumor)\cite{mitosis}, self-driving cars based on pedestrian detections\cite{pedestrian} or recognizing digits taken by Google Street View\cite{svhn}, all using unsupervised learning of features.

This paper propese an in-dept look of solving reinforcement learning problems, using convolutional neural networks. More exactly, we want to design an agent which is capable of learning to play a game\cite{atari} seeing only the pixels from the frames and being rewarded after finishing the game.

This ideea was brought to attention in 2013, when Alex Graves et al. from DeepMind\footnote{\url{http://deepmind.com/}} came with the ideea of creating a convolutional neural network capable of playing different Atari 2600 games, being as good as a game tester. The motivation behind this experiment is not only connected with the fact that we have a machine capable of playing games, but the more important problem is that they achieved the generalization of a machine that could learn several types of games, which in fact is the starting of a new revolution in machine learning. If we are capable of making one unique algorithm that can solve multiple tasks, we are capable of simulating the real human brain and capable of reducing complex problems to another ones, much more simple and thus, we can reduce programming burden and solving problems as cancer classification.



\section{Project description}
\label{sec:proj-description}
This paper presents two different algorithms in creating a good agent which can learn playing games. It is worth mentioning that the agent does not know the rules and can not infere with some rules at the beginning of the game. The whole topic has been splitted in three parts: running Q-Learning on Hanoi Towers game, learning values predicted by Q-Learning using a convolutional neural network and connecting the first two parts together.

First of them is the classical Q-Learning, which is searching the optimal policy for taking actions from each state of the game. We will discus about exploration vs exploitation problem, how to determine the learning rate suitable for our purposes, how many episodes we have to play until we determine a policy close to the optimal one.

The second topic we approach in this paper is how

\section{Technologies}
\label{sec:technologies}
All algorithms described in this paper have been implemented using Torch7\footnote{\url{http://torch.ch/}}, a deep learning framework written in Lua\footnote{\url{http://www.lua.org/about.html}}, a scripting language based on a C API. For creating the game, generating frames or modifying images LOVE platform\footnote{\url{https://love2d.org/wiki/Main_Page}} was the close alternative which is also written in Lua. For interactive computing(image/filter visualization) iTorch\footnote{\url{https://github.com/facebook/iTorch}} has been used.

Why Lua and Torch? They provide a fast environment as opposed to another ones\cite{torch7}, multiple modules with functions already implemented such as transfer functions(tanh, sigmoid), loss functions(Mean Squared Error, Negative Log Likelihood) or convolutional layers(SpatialMaxPooling, SpatialSubSampling)

\section{Structure of this paper}
\label{sec:paper_structure}

\labelindexref{Chapter}{chapter:state} 

\labelindexref{Chapter}{chapter:system-design}    

\labelindexref{Chapter}{chapter:results} 

\labelindexref{Chapter}{chapter:conclusions}

\labelindexref{Chapter}{chapter:future-work}

\section{Copyright infringement}
\label{sec:copyright}
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. 







